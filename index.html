---
layout: main
---
<style>
  img {
    width: 25%;
    float: left;
    margin-right:1rem;
  }
  p {
    overflow: hidden;
  }
</style>
<div class="container">

  <div class="col-xs-12 col-sm-9 col-md-9">

    <div class="row">
    <p>
    I am a <a href='https://research.fb.com/people/daulton-sam/'>research scientist at Facebook</a> on the <a href='https://research.fb.com/teams/core-data-science/'>Core Data Science</a> team and co-creator of <a href='https://botorch.org'>BoTorch</a>, an open source library for Bayesian optimization research. Within Core Data Science, I work in the <a href='https://ai.facebook.com/blog/open-sourcing-ax-and-botorch-new-ai-tools-for-adaptive-experimentation/'>Adaptive Experimentation</a> group led by <a href='http://eytan.github.io'>Eytan Bakshy</a>. My research focuses on methods for principled, sample-efficient optimization including Bayesian optimization and transfer learning. I am particularly interested in practical methods for principled exploration (with probablistic models) that are  are robust across applied problems and depend on few hyperparameters. Furthermore, I aim to democratize such methods by open sourcing reproducible code. Prior to joining Facebook, I worked with <a href='https://finale.seas.harvard.edu/'>Finale Doshi-Velez</a> at Harvard University on efficient and robust methods for transfer learning.
    </p>
    Exploration is a core part of my being, and it's a safe bet that you'll find me climbing, skiing, running, scuba diving, or scheming about how to get to the remote reaches of the world.
    </div>

    <div class="row">
      <h2><a name="publications"></a>Publications</h2>
      <hr>
      <h3>Conference Publications</h3>
      <a href="{{site.baseurl}}/"><img src="{{site.baseurl}}/assets/img/qehvi.jpg" alt="{{site.author}}"></a>
      <p>
        <strong>Differentiable Expected Hypervolume Improvement for Parallel Multi-Objective Bayesian Optimization</strong>
        <br>
        We propose a new state-of-the-art acquisition function for constrained Bayesian optimization of multiple competing objectives. The acquisition function is an exact calculation of expected hypervolume improvement other than monte-carlo integration error. It enables parallel (batch) evaluations via the inclusion-exclusion principle, and it is differentiable, which enables efficient gradient-based acquisition optimization. We prove that the sample average gradient of the Monte-Carlo acquisition is an unbiased estimator of the gradient of the true expected hypervolume improvement.
        <br>
        <strong><a href='http://daulton.github.io'>Samuel Daulton</a></strong>, <a href='https://research.fb.com/people/balandat-max/'>Maxmilian Balandat</a>, <a href='http://eytan.github.io'>Eytan Bakshy</a>
        <br>
        <em>Advances in Neural Information Processing Systems</em> 33, 2020.
        <br>
        <a href="https://arxiv.org/abs/2006.05078" class='btn btn-default'>Paper</a> | <a href="https://botorch.org/tutorials/multi_objective_bo" class='btn btn-default'>Code</a>
      </p>
      <a href="{{site.baseurl}}/"><img src="{{site.baseurl}}/assets/img/botorch_logo_lockup-01.jpg" alt="{{site.author}}"></a>
      <p>

        <strong>BoTorch: Programmable Bayesian Optimization in PyTorch</strong>
        <br>
        We propose a modular Monte-Carlo-based framework for developing new methods for Bayesian optimization. We include multiple examples including a novel one-shot optimization formulation of the Knowledge Gradient. We provide convergence guarantees for a broad class of quasi-Monte-Carlo acquisition functions using the sample average approximation.
        <br>
        <a href='https://research.fb.com/people/balandat-max/'>Maxmilian Balandat</a>,
        <a href='https://research.fb.com/people/karrer-brian/'>Brian Karrer</a>,
        <a href='http://pitt.edu/~drjiang/'>Daniel Jiang</a>,
        <a href='http://daulton.github.io'><strong>Samuel Daulton</strong></a>,
        <a href='http://lethalletham.com/'>Benjamin Letham</a>, <a href='https://cims.nyu.edu/~andrewgw/'>Andrew Gordon Wilson</a>, <a href='http://eytan.github.io'>Eytan Bakshy</a>
        <br>
        <em>Advances in Neural Information Processing Systems</em> 33, 2020.
        <br>
        <a href="https://arxiv.org/abs/1910.06403" class='btn btn-default'>Paper</a> | <a href="https://botorch.org" class='btn btn-default'>Code</a>
      </p>
      <br>
      <a href="{{site.baseurl}}/"><img src="{{site.baseurl}}/assets/img/hipmdp.jpg" alt="{{site.author}}"></a>
      <p>
        <strong>Robust and Efficient Transfer Learning with Hidden Parameter Markov Decision Processes</strong>
        <br>
        We propose a novel algorithm for transfering knowledge between similar, but different reinforcement learning tasks by learning low-dimensional latent embeddings. These embeddings encode task-specific nuances and are provided with the state and action as the input to transition model that is shared across task instances. Modeling the dynamics with a Bayesian neural network enables scalable inference and joint optimization of the network parameters and latent embeddings.
        <br>
        <a href='https://twkillian.github.io/'>Taylor W. Killian</a>*,
        <a href='http://daulton.github.io'><strong>Samuel Daulton</strong></a>*,
        <a href='https://cs.brown.edu/people/gdk/'>George Konidaris</a>, <a href='https://finale.seas.harvard.edu/'>Finale Doshi-Velez</a> (*<em>equal contribution</em>)
          <br>
          [Oral] <em>Advances in Neural Information Processing Systems</em> 30, 2017.
          <br>
          <a href="http://papers.neurips.cc/paper/7205-robust-and-efficient-transfer-learning-with-hidden-parameter-markov-decision-processes" class='btn btn-default'>Paper</a> | <a href="https://github.com/dtak/hip-mdp-public" class='btn btn-default'>Code</a>
      </p>

      <h3>Workshop Papers</h3>
      <a href="{{site.baseurl}}/"><img src="{{site.baseurl}}/assets/img/cts.jpg" alt="{{site.author}}"></a>
      <p>
        <strong>Thompson Sampling for Contextual Bandit Problems with Auxiliary Safety Constraints</strong>
        <br>
        We consider a new class of contextual bandit problems with constraints on auxiliary outcome(s). We consider upper confidence bound and Thompson sampling-based algorithms and perform ablation studies revealing nice properties regarding fairness using the Thompson sampling algorithm. We demonstrate the performance of the algorithm on a real world video transcoding problem.
        <br>
        <strong><a href='http://daulton.github.io'>Samuel Daulton</a></strong>, <a href='https://research.fb.com/people/singh-shaun/'>Shaun Singh</a>, <a href='http://www.columbia.edu/~va2297/'>Vashist Avadhanula</a>, <a href='https://ddimmery.com/'>Drew Dimmery</a>, <a href='http://eytan.github.io'>Eytan Bakshy</a>
        <br>
        <em>NeurIPS Workshop on Safety and Robustness in Decision Making</em>, 2019.
        <br>
        <a href="https://arxiv.org/abs/1911.00638" class='btn btn-default'>Paper</a>
      </p>
      <br>
  </div>
  <br>
  <hr>

<div class="row">
  <h2><a name="Talks"></a>Talks</h2>
  <hr>
  <a href="{{site.baseurl}}/"><img src="{{site.baseurl}}/assets/img/netflix.png" alt="{{site.author}}"></a>
  <p>
    <strong>Practical Solutions to Exploration Problems</strong>
    <br>
    I discuss many practical approaches we use at Facebook for principled exploration including policy optimization with Bayesian optimization via online experiments, constrained Bayesian optimization, multi-task Bayesian optimization accelerated with offline simulations, and contextual bandits.
    <br>
    <strong><a href='http://daulton.github.io'>Samuel Daulton</a></strong>
    <br>
    <em>Netflix ML Platform Meetup on Exploration and Exploitation</em>, 2019.
    <br>
    <a href='https://youtu.be/A-JJvYaBPUU' class='btn btn-default'>Video</a> | <a href="https://www.slideshare.net/FaisalZakariaSiddiqi/facebook-talk-at-netflix-ml-platform-meetup-sep-2019" class='btn btn-default'>Slides</a>
  </p>
</div>


<footer>
&nbsp;
</footer>

<!-- {% for post in paginator.posts %}
<article class="post">
  {% if post.img %}
    <a class="post-thumbnail" style="background-image: url({{"/assets/img/" | prepend: site.baseurl | append : post.img}})" href="{{post.url | prepend: site.baseurl}}"></a>
  {% else %}
  {% endif %}
  <div class="post-content">
    <h2 class="post-title"><a href="{{post.url | prepend: site.baseurl}}">{{post.title}}</a></h2>
    <p>{{ post.content | strip_html | truncatewords: 15 }}</p>
    <span class="post-date">{{post.date | date: '%Y, %b %d'}}&nbsp;&nbsp;&nbsp;â€”&nbsp;</span>
    <span class="post-words">{% capture words %}{{ post.content | number_of_words }}{% endcapture %}{% unless words contains "-" %}{{ words | plus: 250 | divided_by: 250 | append: " minute read" }}{% endunless %}</span>
  </div>
</article>
{% endfor %}

{% include pagination.html %} -->
